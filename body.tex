\input{introduction}

\section{Survey Simulator Overview}
\label{section:simulator}

In operations, the LSST needs an automated scheduler to appropriately plan and execute the $\approx1000$ visits per night. Prior to operations, we have a need to use the same scheduler to understand the range of possible survey strategies and their science potential; even in operations it is useful to run the scheduler in a `simulation' mode in order to evaluate the future impact of changes in observatory hardware or changes to the observing strategy. As such, we need a robust scheduler, together with high-fidelity model inputs for the telescope operations and observing telemetry.  

Probably need some reference to what survey scheduler was used / how it was set up for various runs, how the runs were performed, and what the input weather and telescope models were like. 

\subsection{The Model Observatory}


\subsubsection{Telescope Model}

The physical telescope operations are modeled using the LSST software package \href{https://github.com/lsst-ts/ts_observatory_model}{ts\_observatory\_model}. This package includes a kinematic model of the telescope, with appropriate acceleration/deceleration and maximum velocity limits, including requirements for sequencing (changing the filter before slewing, for example). It also enforces requirements needed before image acquisition, such as the settle time after slewing and the active optics open- and closed-loop acquisition times. Other important considerations are the extent of cable wrap due to azimuth slews or camera rotation. The parameters for the telescope model are configurable, coming from the Telescope and Site and Camera teams. These parameters are largely unchanged from \citet{Delgado14}; a subset of these parameters are described in Table~\ref{tab:tsModel}. 

\begin{table}
\begin{centering}
\begin{tabular}{lc}
\toprule
Parameter  & Value \\
Min altitude  & 20 deg \\
Max altitude & 86.5 deg \\
Camera readout & 2 sec\\
Shutter time & 1 sec \\
Filter change time & 120 sec \\
Number filters mounted & 5 \\
Azimuth slew settle time & 1 sec \\
Closed Optics Loop Delay & 36 sec (when $>9$ deg altitude change) \\
Approximate azimuth slew time &   $ t_{slew \, Az} = 0.66 \, {\rm sec/deg} * \delta Az ({\rm deg}) + C^{Az} $ ;    min = 3 sec \\
Approximate altitude slew time  &  $  t_{slew \, Alt} = 0.57 \, {\rm sec/deg} * \delta Alt ({\rm deg}) + C^{Alt} $ \\
\hline
\end{tabular}
\caption{A subset of ts\_observatory\_model parameters and slew time approximations.}
\label{tab:tsModel}
\end{centering}
\end{table}

\subsubsection{Cloud Model}

The cloud model is based on historical cloud sky coverage data from Cerro-Tololo Inter-American Observatory (CTIO), from the ten year period 1996 to 2005. 

\begin{figure}
\epsscale{0.5}
\plotone{plots/cloud_levels}
\epsscale{1}
\caption{The distribution of cloudiness as measured at CTIO. We model the observatory as closed for cloud levels above 3/10.}
\end{figure}

\begin{figure}
\epsscale{0.5}
\plotone{plots/hours_pernight}
\epsscale{1}
\caption{The average amount of time available per night over the course of a year after removing weather downtime.}
\end{figure}

The SOAR telescope reports losing 15.3-33.4\% (mean=22.9\%) of science time to weather from 2014-2018\footnote{\url{http://www.ctio.noao.edu/soar/content/soar-observing-statistics}}. This is consistent with the weather downtime reported by Gemini South (private communication). 

If we model the observatory as closed when the sky is 30\% cloudy or cloudier, we reach a weather downtime of 29.8\%. While we expect some observations will be possible in 30\% cloudy skies, this cutoff also accounts for other weather related closures (humidity, wind, dust, etc).

\subsubsection{Seeing Model}

\input{seeing}


\subsubsection{Skybrightness Model}

The observatory model includes a model for the sky brightness. The model is built mostly from the ESO sky brightness model which includes upper and lower atmosphere emission lines, airglow continuum, scattered lunar light, and zodiacal light. In addition, we have added a twilight model fit from all-sky camera observations at the site. The sky brightness model does not include human generated light pollution. While the ESO model does include the ability to scale the airglow component with solar activity, we use the default mean solar activity throughout. Compared to all sky camera observations, the skybrightness model has RMS deviations of $\sim$0.2-0.3 magnitudes per square arcsecond \citep{Yoachim16}. 

With so many independent components, the sky brightness is potentially the most computationally expensive aspects of the simulations. We pre-compute sky brightness maps in all six Rubin filters in 5-15 minute time steps which can then be rapidly interpolated to exact times.

\subsubsection{Maintenance Downtime Model}

\begin{figure}
\epsscale{0.5}
\plotone{plots/downtimes}
\epsscale{1}
\caption{The simulated scheduled and unscheduled downtimes over 10 years.}\label{fig:downtime}
\end{figure}

The observatory model includes both scheduled and unscheduled downtime. Figure~\ref{fig:downtime} shows we simulate approximately 10\% of time lost to maintenance. The scheduled downtime allowance is currently about 22 weeks over the full 10 year survey. This is taken in either two one week periods twice a year, or a single two week period in alternating years. The unscheduled downtime allowance is approximately 20 weeks, in variable amounts of time, often as short as a single night. The scheduled downtime is planned during the same periods that are most likely to be bad weather, when possible. 

\subsection{The Scheduler}

Optimally scheduling telescopic observations is a traditionally difficult problem. Most observatories have traditionally scheduled observations by hand. The LCO and ZTF have implemented integer linear programming techniques to optimize their scheduling \citep{Lampoudi15, Bellm19}. Integer programming is difficult to use for Rubin because we have multiple science goals which are intended to be serviced simultaneously. Thus, there is no well-defined value which can be maximized when scheduling Rubin. \citet{Rothchild19} simulated Rubin observations with a very fast deterministic scheduler, essentially repeating a fixed raster pattern mostly along the meridian. This algorithm showed great promise, but had several downsides (such as occasionally pointing at the moon). For the Rubin scheduler, we follow the example in \citet{Naghib19} and use a Markov Decision Process to select most of the observations.

The Rubin scheduler is designed to provide real-time decisions on where and how to observe. Because we expect there to be weather interruptions, we need a system that can recover quickly. Unlike other traditional telescope schedulers, we do not try to optimize a large number of observations in advance, but rather use a decision tree along with a modified Markov Decision Process. The scheduler behavior is set by a small number of free parameters that can be tuned.

Earlier attempts at simulating LSST in \citet{Rothchild19} and \citet{Naghib19}. Eric's scheduler paper. 

Our baseline scheduler uses a three tier decision tree when deciding what observations to attempt. 

\subsubsection{Tier 1:  Deep Drilling Fields}

The first tier of the decision tree is to check if there are any deep drilling fields that should be executed. We typically have five DDFs in a simulation. 

For a DDF to be eligible to send a sequence to the observing queue, it must
\begin{itemize}
\item{Not currently be twilight}
\item{Have enough time to finish a sequence before twilight begins}
\item{Be in it's target hour angle range}
\item{The moon must be down}
\item{The DDF must not have exceeded it's limit of observations (typically $\sim$1\% of the total number of visits)}
\end{itemize}

If the DDF has not fallen behind, it will space sequences by at least 1.5 days. There is also a check to see if the DDF will be feasible and better observed later in the night, in which case no observations are requested.

If the above conditions are met, the DDF sends it's sequence of observations to the queue to be executed. There are currently no attempts at recovery if a sequence is interrupted. 

The spatial position of the DDF is dithered nightly up to 0.7 degrees.  The camera rotator is also varied nightly to be between -75 and 75 degrees with respect to the telescope. 

\begin{table}
\begin{centering}
\begin{tabular}{lcc}
\toprule
    Name &      RA &     Dec \\
    &          (Deg) &  (Deg) \\
    \hline
 ELAISS1 &   9.450 & -44.000 \\
 XMM-LSS &  35.708 &  -4.750 \\
   ECDFS &  53.125 & -28.100 \\
  COSMOS & 150.100 &   2.182 \\
    EDFS &  58.970 & -49.280 \\
    EDFS &  63.600 & -47.600 \\
    \hline
\end{tabular}
\caption{The location of the deep drilling fields used in our simulations.}\label{table:ddfs}
\end{centering}
\end{table}



\subsubsection{Tier 2:  The Blobs}

If there are no DDFs requesting observations, the decision tree moves to the second tier. This tier is the survey workhorse, executing $\sim$80\% of the simulation visits.  This tier will only request observations if it is not currently twilight, and there is at least 30 minutes before twilight begins.

A modified Markov Decision Process (MDP) is used to decide what sky region and filter combination to observe given the current conditions and observation history. Briefly, the MDP balances the desire to observe areas 1) that are closest to the optimal possible in terms of 5-sigma depth, 2) which have fallen behind the specified desired survey footprint, 3) are near the current telescope pointing and 4) in the currently loaded filter to minimize filter changes.  In addition to these core components, the MDP includes a mask around zenith, a 30 degree mask around the moon, and small masks around the bright planets (Venus, Mars, Jupiter). The end product of the MDP is a reward function that ranks the desirability of every point in the sky. Because this tier does not execute in twilight, we assume the reward function is relatively stable on 40 minute timescales.

A sky area around the reward function maximum that will take $\sim$22 minutes to observe ($\sim$35 pointings) is then selected. If possible, the area is selected to be be contiguous.  The exact position of the telescope pointings are determined by the sky tessellation, which is randomly oriented for each night. The camera rotator angle (relative to the telescope) is also randomized between $\pm 80$\ degrees each night.

A traveling salesman algorithm is used to put the pointings in an order that minimizes the slew time. The list of pointings are then repeated, usually in a different filter, ensuring moving objects can be detected.  One of seven possible filter combinations is used: $u+g$, $u+r$, $g+r$, $r+i$, $i+z$, $z+y$, or $y+y$.  We use 30 second visits for the majority of simulations. The official baseline uses visits comprised of two 15 second snaps.  


\subsubsection{Tier 3:  Greedy}

If it is during morning or evening twilight, or close to morning twilight, the DDFs and Blob surveys will pass and the decision tree goes to the third and final tier, the greedy surveys. 

The greedy surveys use a similar Markov Decision Process as in Tier 2, but rather than selecting large areas of sky to observe, the survey selects a single pointing at a time.  No attempt is made to observe greedy scheduled observations in pairs.  Since this tier is primarily used in twilight time, it only schedules observations in the redder filters $r$, $i$, $z$, and $y$.  

As with the Blob tier, the sky tessellation orientation is randomized each night so the final survey is spatially dithered. 



\begin{figure}
\epsscale{0.3}
\plotone{plots/night_plots/baseline_nexp1_v1_6_Count_note_like_DD_and_night810_HEAL_SkyMap.pdf}
\plotone{plots/night_plots/baseline_nexp1_v1_6_Count_note_like_blob_and_night810_HEAL_SkyMap.pdf}
\plotone{plots/night_plots/baseline_nexp1_v1_6_Count_note_like_greedy_and_night810_HEAL_SkyMap.pdf}

\plotone{plots/night_plots/baseline_nexp1_v1_6_altAz_Count_note_like_DD_and_night810_HEAL_SkyMap.pdf}
\plotone{plots/night_plots/baseline_nexp1_v1_6_altAz_Count_note_like_blob_and_night810_HEAL_SkyMap.pdf}
\plotone{plots/night_plots/baseline_nexp1_v1_6_altAz_Count_note_like_greedy_and_night810_HEAL_SkyMap.pdf}
\epsscale{1}
\caption{Examples of how the three scheduler tiers execute during a single night. Left panels show how a DDF sequence was observed during the night. Middle panels show observations taken as part of blob pairs. Right panels show the greedy observations taken in twilight time.  The panels from left to right show the different decision tiers the scheduler uses, with the DDFs as the top tier and the greedy algorithm as the bottom tier. } \label{fig:examplenight}
\end{figure}

\subsection{Filter Mounting Schedule}

In addition to the observations scheduler, we have a separate scheduler that decides which five filters should be loaded for the start of each night.  By default, we mount redder filters ($grizy$) when the moon is more than 40\% illuminated and bluer filters ($ugriy$) closer to new moon. 


\section{Survey Requirements and Metrics}
Basic survey strategy starting point and why - in more depth? Discuss metrics related to these requirements. 

Probably should show that all survey strategies evaluated do / need to meet these requirements (but maybe later?)

\subsection{SRD Metrics}

XXX--Relevant SRD requirements. 825 observations over 18,000 square degrees, fast revisits, and astrometry


XXX--relevant requirement to publish a list of upcoming planned observations (1?2?) hours in advance. 


\subsection{Science Metrics}
\input{metrics_short}

\section{Survey Strategy Experiments} 

Broad outline of points to evaluate for survey strategy, and our approach in running the subsequent experiments (this should help make sense of what comes next)

\section{Feedback from white papers and SAC} 
Broad outline of points to evaluate for survey strategy, and our approach in running the subsequent experiments (this should help make sense of what comes next)

Discuss basic types of SAC recommendations. 


Reformat these, can add science impact highlights, but primary evaluation later. 
\input{runs_v15}

\input{runs_v16}

\section{Science impacts}

The broad categories of experiments covered in the FBS 1.4, 1.5 and 1.6 releases address different aspects of survey strategy. While each family of simulations maintained the approach of varying a single kind of parameter (such as the amount of time devoted to triplets of visits in the `third\_visit' runs or the footprint coverage in the `footprint' runs), the underlying science optimization questions can cover multiple families. In addition, when looking at individual science cases, there can be effects that cover multiple families but have the same underlying cause -- preferring more visits in the WFD or needing more visits in $u$ band, for example .. which can be the result of variations in survey strategy in multiple different families (i.e. we get to the same place via different means). 

\subsection{Individual Visit Length}
What to do - 1x30s vs. 2x15s? 1x30s much more efficient (show rough calculation of overhead) than 2x15s, but may have drawbacks due to cosmic ray rejection and potential to miss very rapid transients (or WD detection .. ref white paper). Subtle drawback that 2x15s gives the same "midpoint exposure time" across FOV, 1x30s does not. 

Show difference in 1x30s vs. 2x15s in whatever is our 'standard baseline' at this point. 

There has been thought of using a variety of exposure times if we use two snaps (e.g., 5s + 25s). Because there are not plans to release catalogs from individual snaps, it's not clear if this would enable much new science.

Show effect of 7\% loss in efficiency when attempting to combine minisurveys in various configurations (assume we will find some combinations possible with single exposure visits that are impossible with two snaps). 

Also possible to use variable exposure time depending on seeing and sky brightness conditions. Shorter exposures in good conditions keeps us from observing ``wasted" depth, letting us take longer exposures in poor conditions. This does introduce a host of new free parameters (an ideal target depth for each filter and minimum and maximum exposure times).  This would might require rewording the SRD to ensure, e.g., that 20s visits in good conditions count for the number of visit requirement.

Relevant metrics: total number of visits, number of visits per field/filter

\subsection{Intra-night Cadence}

What to do for visit sequence within a night? White paper support for multiple filters within a night (except TNOs maybe?). Potential drawbacks - less efficient (show effect on efficiency). This applies to WFD primarily, but we've applied to any survey that did not have their own specifications (so, everywhere). 

Extension of pairs to $u$ band and $y$ band (show effect). 

Relevant metrics: inter-night visit gaps and SN discovery, SSO discovery/characterization, transient and variable discovery (??), number of visits

\subsection{Survey Footprint}
What to do for WFD footprint? SRD not specific, DESC want low-extinction sky (and depth), but WFD is generally the area of sky that receives the most visits, so generally other science will also benefit from more visits to their relevant areas (particularly galactic plane .. for time-domain studies primarily, not depth)

Relevant metrics: area of sky with 825 visits (under particular restrictions, like total coadded depth and individual image seeing and dust extinction), number of galaxies, number of resolved galaxies, SSO discovery, transient and variable star discovery, astrometry in the galactic plane (?)

\subsubsection{Northern minisurveys}
Add extension to cover Euclid/DESI with various numbers of visits

Observing NES 

Effect of adding or removing these minisurveys

Relevant metrics: SSO discovery and characterization (particularly active asteroids), depth and number of visits through remainder of North

\subsubsection{Southern minisurveys}
Add extension over south celestial pole, LMC/SMC with various numbers of visits

Effect of adding or removing these minisurveys

Relevant metrics: number of visits and coadded depth over SCP, discovery of variables in LMC/SMC (see Olsen white paper for metrics?)

\subsubsection{Low Galactic Latitudes}
Discussion of definitions from SAC and recommendations for visits

Effect of adding or removing these minisurveys

Relevant metrics: number of visits, astrometry in bulge, discovery of variables/transients/microlensing in bulge (?)


\subsection{Rolling cadence}
Motivation for a rolling cadence (more frequent visits in some years)

Different options for rolling and explanation of how implemented

Should really include discussion of recovery from bad weather years and simulation of same

Relevant metrics: Maintain astrometry requirements, SN discovery, SSO discovery and characterization,  Transient and variable discovery, uniformity of coadded depth / number of visits, 



\subsection{Twilight Observing}
Discuss need for twilight observing to meet SRD goals (weather, total amount of time available)

Add NEO twilight survey, add DCR white paper (season extension visits?)

Effect of adding or removing these minisurveys

Relevant metrics: NEO discovery, number of visits and coadded depth (and uniformity) in WFD, measurement of DCR, season length

\subsection{Deep Drilling Fields}
Discuss purpose and how these are scheduled (very different from other fields)

Discuss potential cadences (AGN/ DESC) and how these differ, and our combination of the two

Discuss timing issues with oversubscription (and how much of a problem this could be, what if worse weather?) -- include location of fifth DD field

Effect of adding or removing these minisurveys

Relevant metrics: number of visits and coadded depth for DD, SN detection in DDFs, AGN detection in DDFs
*[solar system minisurvey DDF?]

\subsection{ToO modes}
Discuss impact of ToO, and how we could implement ToOs in scheduler (various modes: straight to queue by hand or set up known program and supply trigger, etc. -- that we're evaluating the second?)

Any ToO survey should also take into account that chip and raft gaps mean full sky coverage will require multiple images with spatial dithering.

Discuss how we can have a low coverage region to the north to maintain templates for all possible ToOs, or we could decide ot only search for ToOs that are likely to be in the WFD area.

Relevant metrics: frequency of achieving ToO observations, number of visits and coadded depth in other surveys (WFD or other minisurveys that may be in particular contention)

\subsection{Number of visits in WFD}
Overall survey number of visits vs. number of visits in WFD (see twilight survey, DCRham surveys, variable exposure, shortexp surveys)


\section{Conclusions}
Hopefully here we pare down the evaluation of 100s of runs (like promised) to a set of between 10 to 20 (if this is possible, after combining along different axes). 
The results should come with some basic comments about what's particularly good or bad in each of these areas and how we arrived at these general options. 

Metrics we know we need to get from the community:
\begin{itemize}
    \item{Photometric redshift performance, especially as it relates to filter distribution}
    \item{Weak Lensing systematics, especially as related to camera rotator angle}
    \item{Deep Drilling Field metrics beyond coadded depth (e.g., AGN performance)}
    \item{Deep Drilling metrics that are sensitive to the spatial dither strategy}
    \item{Transient early classification metric}
    \item{More populations in the Galactic plane beyond the simple number of stars.}
\end{itemize}

\input{questions}


% Make sure lsst-texmf/bin/generateAcronyms.py is in your path
\section{Acronyms} \label{sec:acronyms}
\input{acronyms.tex}
