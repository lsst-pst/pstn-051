
\section{Outstanding Questions}\label{sec:questions}

Here we go through some of the outstanding questions that the SCOC and scientific community can help resolve in order to converge on a final scheduler strategy for the Rubin Observatory. 

\subsection{Exposure Time(s)}

We will probably need on-sky data to make a final answer to this question, but we need to eventually decide how many snaps to take in a visit. We have run the baseline simulation with both 1x30s visits and 2x15s visits. Another possibility is using variable exposure times to make the single visit depths more uniform.

Other questions related to exposure time
\begin{itemize}
    \item{Should we change the u-band to default to 60 second exposures to ensure they are not readnoise dominated? This might require decreasing the SRD 825 visit value. This choice would also severely limit $u$\ band time domain science (e.g., TDE early detection)}
    \item{Should we include some very short exposure time exposures. That would let us have better tie-in with other surveys (e.g., Gaia).  It is relatively little exposure time, but the readout time means it is a low-efficiency way to operate the telescope.}
    \item{Should we decrease the exposure time in twilight to keep the saturation level reasonable?}
    \item{Should we use variable exposure times so individual exposures have more uniform depth? In poor observing conditions, we would have fewer exposures that were londer and in good conditions we would have more observations that are shorter.}
\end{itemize}


\subsection{Pairs and Filter Choice}

There is a strong preference to take observations in pairs. Closely spaced observations let the pipeline identify moving objects. Similarly, observations in different filters are essential for transient classification. 

The baseline survey (and most of our other experiments), take pairs in neighboring filters (e.g., u+g, g+r, etc).  We should verify that this is a good pairing strategy. Similarly, we have done experiments where we attempt to observe a third observation in a night. 

Taking pairs in different filters does increase time spent changing filters, but it's something like a 4\% hit that seems totally worth the science gain so far. 

Our baseline strategies heavily prefer to take y-band observations in bright time. While this is optimal for the possible SNR, it can result in long gaps between observations in bluer filters. 

Similarly, we could expand or constrict the filters we pursue in twilight time. XXX--some 1.5 runs I think that vary which filters we run in twilight.

\subsection{Survey Contingency}

How much contingency should we aim for when designing the survey strategy?  Currently, with what we believe is a conservative weather closure policy, we can meet SRD requirements with 2x15s visits, but can cover a larger footprint and do more science cases with 1x30s snaps.  

\subsection{Deep Drilling Fields}

We have run a variety of Deep Drilling strategies. The DDF strategy is largely separable from the rest of the survey design, and we have a number of proposals for DDFs that we have yet to explore (e.g., rolling DDFs where a single DDF is completed in one observing season).  We have started experimenting with pre-scheduling DDF observations. 

\begin{itemize}
    \item{What fraction of the survey should be dedicated to the DDFs?}
    \item{Should DDFs be preferentially executed in dark time, or is it more important to maintain cadence?}
    \item{Where should the DDFs be placed (can we finalize the 5th DDF as a Euclid double-pointing)?}
    \item{What is the preferred dithering strategy (spatially and rotationally) for the DDFs? There is tension in that DM generally prefers larger dithers for calibration and co-addition purposes, while science cases prefer smaller dithers to preserve the area that reaches the deepest levels.}
    \item{Should we try ``rolling" the DDFs, completing DDF observations in a field in only a few years?}
\end{itemize}

\subsection{Rotational Dithering}

By default, we select a random camera rotation angle (wrt the telescope) nightly. This creates minimal additional slewtime, and seems to provide adequate angular randomization.  We currently have no science metrics that depend on the angular distribution, and this should be something very important to weak lensing science (although we do not have a metric to measure this).

We have also experimented with setting the camera rotation angle to ensure stellar diffraction spikes fall preferentially along rows and columns. 

\begin{itemize}
    \item{How should we rotationally dither visits?}
\end{itemize}

\subsection{Spatial Dithering}

For the wide area regions we have had excellent results randomizing the tessellation orientation nightly. This does result in a small percent of time being spent observing outside the desired survey footprint. The alternative would be to limit the amount one dithers out of the footprint, but then one risks imprinting systematics on objects near the footprint border (e.g., an object is never observed in the center of the focal plane, only by outer rafts).

% XXX--There's no question here, the SCOC doesn't have to say anything about dithering in the wide area surveys.

\subsection{Survey Footprint}

Perhaps the biggest question, what should we set the survey footprint to be?

\begin{itemize}
    \item{How should we cover the Galactic plane?}
    \item{How should we observe the Galactic bulge?}
    \item{Should we avoid areas of high dust extinction for the WFD area?}
    \item{What is the ideal filter distribution to use? It would be nice to have a photo-z metric to help make this decision.}
    \item{What is the ideal filter distribution in the GP and SCP?}
    \item{Should we cover the LMC and SMC as part of the WFD survey? As their own DDF-like survey? We have few metrics that touch on LMC/SMC science directly.}
    \item{Should we add area in the north to overlap with Euclid, WFIRST, and/or DESI?}
\end{itemize}

Once the general survey footprint is decided, we can fine-tune the footprint (e.g., tapering the WFD region slightly around the RA with multiple DDFs, and flaring at under-subscribed RAs).

\subsection{Rolling Cadence}

We have gone through several iterations of rolling cadence, and now have started to converge on a technique that does not seem to impact the final survey depth. 

\begin{itemize}
    \item{Should we use a rolling cadence strategy?}
    \item{Should we roll just the WFD area, or other regions as well?}
\end{itemize}

\subsection{Best Use of Twilight Time}

Our baseline simulation uses twilight time to fill in WFD observations in redder filters ($rizy$). We can use some of the time to conduct a NEO survey. We can also vary which filters get used in twilight time. The baseline greedy algorithm used in twilight is known to be rather unstable, so we could also try running more contiguous blocks in twilight. We could also emphasize targeting areas that have already been observed 4 or more times in the night, potentially gathering important color information for a small number of transients.


\subsection{Target of Opportunity}

Currently, the only expected ToO use of Rubin observatory is follow up of gravitational wave detections.

\begin{itemize}
    \item{When should Rubin interrupt observations to look for GW optical counterparts?}
    \item{Do we look for GW events in the WFD area, or anywhere on the sky?}
    \item{Should we expand the survey footprint so we have image differencing templates over the entire accessible sky, in at least a few filters?}
    \item{Should Rubin plan on observing the entire light curve of ToO events, or make observations primarily for detection/classification and leave detailed follow up to other observatories?}
    \item{What filter combination and dither strategy (filling chip and raft gaps) should be used for observing ToO triggers? } 
\end{itemize}


\subsection{Image Differencing Templates, DCR}

Do we need to do anything special to ensure we have adequate image templates? A certain number of observations per year? A certain fraction of images taken in good seeing conditions? 

If we need to start considering image quality, that makes it more difficult to simulate a night ahead of time and maintain the list of upcoming observations.

Should we intentionally extend to high airmass to facilitate DCR modeling? Note that in the baseline, we only image a location in the WFD region $\sim$9 times per year in $g$ and $\sim$6 times in $u$. Also, we have chip and raft gaps, so if we want to build a DCR model for the entire sky in $g$, we might be dedicating 1/3 of the $g$ observations in a year to DCR. If we switch to 60s $u$ band exposures, there would be no observations beyond building the DCR model. 

There have been claims that measuring DCR can be used for science.  We do not have any metrics that demonstrate any gains, and the loss of depth is noticeable. In theory, we could combine the DCR measurements to extend the season length of observations as well (e.g., only take DCR template images near twilight in the direction of the sun).

\subsection{Satellite Megaconstellations}

Starlink is poised to launch thousands of LEO satellites. Observations so far imply that final-orbit Starlink satellites should not saturate Rubin exposures, and thus can be masked fairly easily in the image reduction pipeline. 

Do we need any further satellite mitigations? Will NEO twilight surveys still be viable in the presence of megaconstellations, or should we use twilight strategies that avoid the horizon?

Figure~\ref{fig:megasat} shows how illuminated megaconstellations in LEO would leave numerous streaks on Rubin images.

% from https://github.com/yoachim/satellite_collisions
\begin{figure}
\plottwo{plots/sat_plots/ten_min_12k.pdf}{plots/sat_plots/tenmin_example.pdf}
\caption{Alt/az projection of simulated satellite megaconstellations as seen from the Rubin Observatory site after twilight has ended. } \label{fig:megasat}
\end{figure}

